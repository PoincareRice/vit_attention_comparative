# ğŸ§  ViT Attention Comparative  
### Comparative Analysis of Advanced Attention Mechanisms in Vision Transformers  
**ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸(ViT)ì—ì„œ ê³ ê¸‰ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜(Entmax, Sparsemax ë“±)ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” í”„ë¡œì íŠ¸**

-

## ğŸ“˜ Overview | ê°œìš”

This repository provides a complete implementation for comparing **advanced attention mechanisms** (such as *Entmax* and *Sparsemax*) in **Vision Transformers (ViT)**.  
It supports training, evaluation, and visualization of attention maps on **CIFAR-10**.

ì´ ì €ì¥ì†ŒëŠ” **Vision Transformer(ViT)** ì—ì„œ **Entmax, Sparsemax ë“± ê³ ê¸‰ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**ì„ ë¹„êµ ì‹¤í—˜í•˜ê¸° ìœ„í•œ ì „ì²´ êµ¬í˜„ì„ ì œê³µí•©ë‹ˆë‹¤.  
**CIFAR-10** ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ, í‰ê°€, ì–´í…ì…˜ ë§µ ì‹œê°í™”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

---

## ğŸ“‚ Project Structure | í”„ë¡œì íŠ¸ êµ¬ì¡°

```
VIT_ATTENTION_COMPARATIVE/
â”œâ”€â”€ bash_folder/               # Shell scripts for training & evaluation | í•™ìŠµ/í‰ê°€ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train.bash
â”‚   â””â”€â”€ evaluate.bash
â”œâ”€â”€ configs/                   # Experiment and model configuration files | ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ experiment1.yaml
â”œâ”€â”€ data/                      # Dataset storage (CIFAR-10) | ë°ì´í„° ì €ì¥ ê²½ë¡œ
â”‚   â”œâ”€â”€ external/              # Raw/external data | ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ experiments/               # Experiment results | ì‹¤í—˜ ê²°ê³¼ ì €ì¥
â”‚   â””â”€â”€ exp_001/
â”‚       â”œâ”€â”€ checkpoints/       # Model checkpoints | ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥
â”‚       â”œâ”€â”€ logs/
â”‚       â””â”€â”€ results/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                  # Dataset loaders | ë°ì´í„°ì…‹ ë¡œë”
â”‚   â”œâ”€â”€ evaluation/            # Evaluation scripts | í‰ê°€ ì½”ë“œ
â”‚   â”œâ”€â”€ models/                # Model definitions | ëª¨ë¸ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ attention/
â”‚   â”‚   â”‚   â”œâ”€â”€ base_attention.py
â”‚   â”‚   â”‚   â”œâ”€â”€ entmax_attention.py
â”‚   â”‚   â”‚   â””â”€â”€ sparsemax_attention.py
â”‚   â”‚   â””â”€â”€ vit_custom.py
â”‚   â”œâ”€â”€ training/              # Training scripts | í•™ìŠµ ì½”ë“œ
â”‚   â””â”€â”€ utils/                 # Utility functions | ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ tests/                     # Unit tests | í…ŒìŠ¤íŠ¸ ì½”ë“œ
â””â”€â”€ requirements.txt
```
---

## âš™ï¸ Installation | ì„¤ì¹˜ ë°©ë²•

```bash
# Clone repository | ì €ì¥ì†Œ ë³µì œ
git clone https://github.com/PoincareRice/vit_attention_comparative.git
cd VIT_ATTENTION_COMPARATIVE

# Create virtual environment (optional) | ê°€ìƒí™˜ê²½ ìƒì„± (ì„ íƒ)
conda create -n vit-env python=3.10 -y
conda activate vit-env
#ubuntu22.04
python3.10 -m venv vit-env
source ./vit-env/bin/activate

# Install dependencies | í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```
---
## ğŸš€ Usage | ì‚¬ìš© ë°©ë²•

### Training | í•™ìŠµ ì‹¤í–‰
```bash
bash ./bash_folder/train.bash
```
Trains a ViT model using the selected attention mechanism (softmax, entmax, or sparsemax).
Saves checkpoints under experiments/<exp_name>/checkpoints/.

ì„ íƒí•œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜(softmax, entmax, sparsemax)ìœ¼ë¡œ ViT ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
ê²°ê³¼ ê°€ì¤‘ì¹˜ëŠ” experiments/<exp_name>/checkpoints/ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.

### Evaluation | í‰ê°€ ì‹¤í–‰
```bash
bash ./bash_folder/evaluate.bash
```
Evaluates a saved checkpoint and visualizes attention maps.
Results are stored under experiments/<exp_name>/results/.

ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì™€ ëª¨ë¸ì„ í‰ê°€í•˜ê³  ì–´í…ì…˜ ë§µì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” experiments/<exp_name>/results/ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.

